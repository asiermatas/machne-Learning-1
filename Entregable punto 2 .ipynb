{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Implementación de una regresión “stepwise” con eliminación hacia atrás.\n",
    "\n",
    "Utilizando como referencia el código del algoritmo “stepwise” con selección hacia adelante(Fordward Stepwise Regression) realizar una implementación del del algoritmo con eliminación hacia atrás (Backward Stepwise Regression). \n",
    "\n",
    "En este caso la selección de las variables se realiza empezando con un modelo que utiliza todas la variables disponibles para ir eliminando en cada paso la produce el modelo menos significativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Primero, como siempre, importamos las librerias que vamos a necesitar\n",
    "\n",
    "import numpy \n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# La siguiente función es una Fordward Stepwise Regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def forward_regression(x, y):\n",
    "    \n",
    "# Obtencion del conjunto de datos para validación\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "# Modelo para realizar los ajustes\n",
    "\n",
    "    model = LinearRegression()\n",
    "\n",
    "# Variable para almecena los índices de la lista de atributos usados\n",
    "\n",
    "    feature_list = list(x.columns)\n",
    "    feature_order = []\n",
    "    feature_error = []\n",
    "    feature_names = []\n",
    "\n",
    "# Iteración sobre todas las variables\n",
    "\n",
    "    for i in range(len(feature_list)):\n",
    "        idx_try = [val for val in range(len(feature_list)) if val not in feature_order]\n",
    "        iter_error = []\n",
    "\n",
    "        for i_try in idx_try:\n",
    "            useRow = feature_order[:]\n",
    "            useRow.append(i_try)\n",
    "\n",
    "            use_train = x_train[x_train.columns[useRow]]\n",
    "            use_test = x_test[x_train.columns[useRow]]\n",
    "\n",
    "            model.fit(use_train, y_train)\n",
    "            rmsError = numpy.linalg.norm((y_test - model.predict(use_test)), 2)/sqrt(len(y_test))\n",
    "            iter_error.append(rmsError)\n",
    "\n",
    "        pos_best = numpy.argmin(iter_error)\n",
    "        \n",
    "        if len(feature_error) == 0 or (iter_error[pos_best] < feature_error[-1]):\n",
    "            feature_order.append(idx_try[pos_best])\n",
    "            feature_error.append(iter_error[pos_best])\n",
    "            feature_names.append(feature_list[idx_try[pos_best]])\n",
    "            print (\"Paso\", len(feature_error), \"se añade variable\", feature_list[idx_try[pos_best]], \"con RMS\", iter_error[pos_best])\n",
    "        else:\n",
    "            return feature_names, feature_error, feature_names\n",
    "\n",
    "    return feature_names, feature_order, feature_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Paso', 1, 'se a\\xc3\\xb1ade variable', 'alcohol', 'con RMS', 0.80501937589589667)\n",
      "('Paso', 2, 'se a\\xc3\\xb1ade variable', 'volatile acidity', 'con RMS', 0.77698521127299414)\n",
      "('Paso', 3, 'se a\\xc3\\xb1ade variable', 'free sulfur dioxide', 'con RMS', 0.76979472187183295)\n",
      "('Paso', 4, 'se a\\xc3\\xb1ade variable', 'sulphates', 'con RMS', 0.76750071270120357)\n",
      "('Paso', 5, 'se a\\xc3\\xb1ade variable', 'fixed acidity', 'con RMS', 0.76569996405671281)\n",
      "('Paso', 6, 'se a\\xc3\\xb1ade variable', 'residual sugar', 'con RMS', 0.76356375248850084)\n",
      "('Paso', 7, 'se a\\xc3\\xb1ade variable', 'density', 'con RMS', 0.76084767429032674)\n",
      "('Paso', 8, 'se a\\xc3\\xb1ade variable', 'pH', 'con RMS', 0.75678229846541079)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['alcohol',\n",
       "  'volatile acidity',\n",
       "  'free sulfur dioxide',\n",
       "  'sulphates',\n",
       "  'fixed acidity',\n",
       "  'residual sugar',\n",
       "  'density',\n",
       "  'pH'],\n",
       " [0.80501937589589667,\n",
       "  0.77698521127299414,\n",
       "  0.76979472187183295,\n",
       "  0.76750071270120357,\n",
       "  0.76569996405671281,\n",
       "  0.76356375248850084,\n",
       "  0.76084767429032674,\n",
       "  0.75678229846541079],\n",
       " ['alcohol',\n",
       "  'volatile acidity',\n",
       "  'free sulfur dioxide',\n",
       "  'sulphates',\n",
       "  'fixed acidity',\n",
       "  'residual sugar',\n",
       "  'density',\n",
       "  'pH'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos a utilizar la función Fordward Stepwise Regression sobre los datos de los vnos\n",
    "\n",
    "wine = pd.read_csv('winequality-white.csv', sep = ';') \n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Separación de la variable objetivo y las explicativas\n",
    "\n",
    "target = 'quality'\n",
    "features = list(wine.columns)\n",
    "features.remove('quality')\n",
    "\n",
    "x = wine[features]\n",
    "y = wine[target]\n",
    "\n",
    "# Obtencion del conjunto de datos para validación\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "forward_regression(x, y)  \n",
    "\n",
    "# vemos como va bajando el error del modelo según se van añadiendo nuevas variables y asi baja de 0.80501937589589667 a \n",
    "# 0.75678229846541079. Aunque cada vez se mejora menos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ahora vamos a hacer Backward Stepwise Regression\n",
    " \n",
    "def backward_regression(x, y):\n",
    " \n",
    "    # Obtencion del conjunto de datos para validación\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "# Modelo para realizar los ajustes\n",
    "\n",
    "    model = LinearRegression()\n",
    "\n",
    "    feature_order = range(len(features))\n",
    "    feature_error = []\n",
    "    feature_names = []\n",
    "\n",
    "    for i in range(len(features)-1):\n",
    "        idx_try = [val for val in range(len(features)) if val in feature_order]\n",
    "        iter_error = []\n",
    "\n",
    "        for i_try in idx_try:\n",
    "            useRow = feature_order[:]\n",
    "            useRow.remove(i_try)\n",
    "\n",
    "            use_train = x_train[x_train.columns[useRow]]\n",
    "            use_test = x_test[x_train.columns[useRow]]\n",
    "\n",
    "            model.fit(use_train, y_train)\n",
    "            rmsError = numpy.linalg.norm((y_test - model.predict(use_test)), 2)/math.sqrt(len(y_test))\n",
    "            iter_error.append(rmsError)\n",
    "\n",
    "        pos_best = numpy.argmin(iter_error)\n",
    "        \n",
    "        feature_order.remove(idx_try[pos_best])\n",
    "        feature_names.append(idx_try[pos_best])\n",
    "        feature_error.append(iter_error[pos_best])\n",
    "\n",
    "\n",
    "    for i in range(len(features)-1):\n",
    "        print (\"Paso\", i, \"se ha eliminado la variable\", features[feature_names[i]], \"con un error\", feature_error[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Paso', 0, 'se ha eliminado la variable', 'fixed acidity', 'con un error', 0.76038809393349582)\n",
      "('Paso', 1, 'se ha eliminado la variable', 'sulphates', 'con un error', 0.75982763982089452)\n",
      "('Paso', 2, 'se ha eliminado la variable', 'citric acid', 'con un error', 0.75972809559318311)\n",
      "('Paso', 3, 'se ha eliminado la variable', 'chlorides', 'con un error', 0.75969527876808296)\n",
      "('Paso', 4, 'se ha eliminado la variable', 'total sulfur dioxide', 'con un error', 0.75973974913404729)\n",
      "('Paso', 5, 'se ha eliminado la variable', 'pH', 'con un error', 0.76266356881547548)\n",
      "('Paso', 6, 'se ha eliminado la variable', 'density', 'con un error', 0.76566857455974424)\n",
      "('Paso', 7, 'se ha eliminado la variable', 'free sulfur dioxide', 'con un error', 0.77133465495560505)\n",
      "('Paso', 8, 'se ha eliminado la variable', 'residual sugar', 'con un error', 0.78424692949402808)\n",
      "('Paso', 9, 'se ha eliminado la variable', 'volatile acidity', 'con un error', 0.81300475226533242)\n"
     ]
    }
   ],
   "source": [
    "# ahora utilizamos la nueva función de Backward Stepwise Regression nuevamente con el csv de los vinos\n",
    "import math\n",
    "backward_regression(x, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# así vemos como se van eliminando variables, al princpio va bajando el error del modelo (de 0.76038809393349582)\n",
    "# hasta quedar en un 0.75969527876808296.\n",
    "# Pero al seguir eliminando variables, el error del modelo empieza a subir hasta el 0.81300475226533242\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
